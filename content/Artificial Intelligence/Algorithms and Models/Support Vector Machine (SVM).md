
## **Support Vector Machine (SVM)**

🔹 **Type:** Supervised Learning (Classification & Regression)  
🔹 **Best For:** High-dimensional data, small datasets

### **How it Works:**

- SVM finds the **best decision boundary** (hyperplane) that separates different classes in the dataset.
- Uses **support vectors** (data points closest to the boundary) to maximize the margin between classes.

### **Pros:**

✅ Works well with high-dimensional data  
✅ Effective for small datasets  
✅ Can handle non-linear classification with **Kernel Tricks** (e.g., RBF Kernel)

### **Cons:**

❌ Computationally expensive for large datasets  
❌ Hard to tune hyperparameters

### **Example:**

- **Face recognition** – SVM classifies images as "face" or "not face".
- **Cancer detection** – Classifies tumors as malignant or benign.


![[Pasted image 20250129122634.png]]

[[Classification using Naive Bayes, Decision Trees, SVM, with Bag-Of-Words and TF-IDF]]

