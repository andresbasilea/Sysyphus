---
draft: true
---

¿Qué buscamos?

**Conocimientos Técnicos:**
- Dominio de los servicios y soluciones de GCP (Compute Engine, App Engine, Cloud Storage, BigQuery, Looker).
- Experiencia en arquitectura de nube, incluyendo redes, virtualización, identidad, seguridad, business continuity, recuperación de desastres y gobernanza de datos.
- Conocimientos en contenedores y su orquestación.
_-_ Conocimientos en bases de datos cloud y herramientas de replicación de datos
- Comprensión de principios de DevOps y herramientas asociadas (CI/CD, monitoreo, logging).

**Habilidades de Implementación y Desarrollo:**
- Capacidad para diseñar, desarrollar e implementar soluciones escalables, seguras y rentables en GCP.
- Experiencia en la migración de aplicaciones, datos y servicios desde entornos locales o de otras nubes a GCP.
- Conocimiento en el uso de herramientas de automatización e infraestructura como código (Terraform, Cloud Deployment Manager).

**Certificaciones y Educación:**
- Certificaciones relevantes de GCP, como Google Cloud Certified - Professional Cloud Architect o Google Cloud Certified - Professional Data Engineer.
- Formación en informática, ingeniería de sistemas o campos relacionados.

**Seguridad y Conformidad:**
- Experiencia en la configuración y gestión de políticas de seguridad en GCP.

**Optimización y Soporte:**
- Habilidad para optimizar costos y rendimiento de las soluciones en GCP.
- Experiencia en proporcionar soporte técnico y resolver problemas en entornos de GCP.

**Se valorará de forma especial:**

- Apasionado de la tecnología. Completamente al día de las últimas tendencias de la industria.- Habituado a trabajar por objetivos. Acostumbrado a trabajar bajo presión en entornos altamente exigentes.- Buen comunicador, sabrá transmitir ilusión al entorno de trabajo.- Comprometido. Capacidad de análisis y solución de problemas.- Buenas habilidades de negociación.- Capaz de generar empatía tanto con los empleados y clientes.- Capaz de adaptarse a la cultura de trabajo de una pyme. Sin grandes jerarquías. Compatibilizando la capacidad de trabajar con autonomía con un fuerte espíritu de colaboración y, sobre todo, de trabajo en equipo.- Interesado en desarrollar su carrera profesional en entornos altamente competitivos y con alto potencial de crecimiento.

**Perfil del candidato/a ideal:**

- Eres un apasionado/a de la tecnología y estás siempre al día con las últimas tendencias de la industria.- Estás acostumbrado/a a trabajar por objetivos y en entornos altamente exigentes.- Tienes habilidades excepcionales de comunicación y sabes transmitir entusiasmo en el trabajo.- Eres una persona comprometida, con fuertes habilidades de análisis y resolución de problemas, así como habilidades de negociación.- Puedes establecer una conexión empática tanto con los compañeros de trabajo como con los clientes.- Te adaptas fácilmente a la cultura de trabajo de una empresa donde no hay grandes jerarquías y se valora la autonomía, la colaboración y el trabajo en equipo.- Estás interesado/a en desarrollar tu carrera en un entorno altamente competitivo con un gran potencial de crecimiento.

**En Bluetab, te ofrecemos:**
- Contrato indefinido, posterior al periodo de prueba, con un salario competitivo, basado en tus habilidades técnicas y el rol asignado, con posibilidad de ajustes conforme a tus evaluaciones de desempeño.- Formación continua.- Plan de carrera individualizado en áreas técnica, funcional o de gestión (¡Tú decides, pero siempre continuamos formándonos!).- Beneficios sociales que van más allá del salario, como un fondo de ahorro, seguros médicos para ti y tu familia, vales de despensa, vacaciones superiores a las establecidas por ley y más.

¿Qué estás esperando para unirte a Bluetab, an IBM Company? ¡Queremos saber de ti pronto!

**Muchas gracias por compartirme tu información, me interesa bastante tu perfil. Sin embargo, nuestro margen salarial solo nos permite ofertarte hasta $35,000 brutos, con nuestras prestaciones superiores de la ley como Vales de despensa de $2,047 al mes, Seguro de gastos médicos mayores y menores, 18 de vacaciones al año, Bolsa de capacitación de 10,000 al año, apoyo emocional de $1,500 al año, bono de bienestar de $15,000 también al año más convenios exclusivos de Bluetab.**


BLUETAB:

Empresa fundada en el año 2006 entre el reino unido y españa. Es una empresa multinacional especializada en consultoría tecnológica y soluciones avanzadas en el ámbito de los datos y la analítica. Se enfoca en ayudar a las grandes organizaciones a transformar sus procesos de gestión, integración y explotación de datos. 

En 2021 bluetab fue adquirida por IBM, lo cual terminó de consolidar su presencia a nivel internacional y he visto que trabajan muy de la mano con empresas como BBVA. 


### Present Yourself

Hi! My name is Andrés Basile, I am 25 years old. I was born in Argentina, but I have been living in Mexico for almost my whole life. I am a Computer Engineer passionate about data, data engineering and Artificial Intelligence, topics which I specialized on during my time at college at the National Autonomous University of Mexico, from which I graduated as the second best average of my generation. 

I currently work as a Presales Data Engineer which means that I am the middleground between the technical specialists and the commercial area of the company I work on. The company is called Edicom, which is a technology and SaaS solutions provider based off in Valencia, Spain,  where I lived and worked for a couple of months this year. My work mainly consists on translating business requirements into technical architectures. or transforming the need into a design which fits our current technical platform. 

At my time in college I gained foundational knowledge in software development, data engineering, and Artificial Intelligence, and I have also proactively taken steps to grow my expertise by developing my own projects, taking courses and consolidating my knowledge with certifications such as the Google cloud Professional data engineer certification. 

I am also a great advocate of what is called "learning in public", I currently write blog entries on my personal website, trying to transmit my experience and knowledge, and I think this translates perfectly into a business environment where it is crucial to be able to communicate our learnings, our wrongdoings and do so effectively to try and build a team of peers that can adapt and overcome any type of project. 

Looking ahead, I am ready to step into a full data egineering or data platform engineer role, where I can continue to grow my technical skills and eventually become an expert in the field. 
### Strengths
- Honesty: I firmly believe that it is better to say "I don't know" than to try and invent some answer. 
- Responsible: I am very responsible person, not only in the sense of fulfilling my obligations or responsibilities within the estimated time frame, but also in the sense of holding myself accountable for my mistakes. 
- Avid and fast learner: I love learning new topics, new technologies, working on new projects and I believe that I can do so very quickly, specially regarding the topics that I love most.  I tend to put the upmost passion into what I am doing and I believe this is a great catalyst for growth. 
### Weaknesses
- I believe that regarding this specific role, one of my weaknesses might be that I have limited formal experience in managing data platforms independently. However, I have been proactively seeking opportunities to develop these skills and I have even taken steps on my current role to try and make it more data and technically oriented by taking ownership of small initiatives like analyzing response times on our solutions, or studying our technical architecture to understand it and communicate it with my peers and even potential clients.
- Limited exposure to certain tools or platforms like NiFi, IDMC, or some AWS solutions. I view this as an opportunity for growth and I want to be able to apply these technologies in real-world projects. 

### Difficult time professionally 

From my experience working in technical and middle-ground positions, one of the most enduring professional challenges I’ve faced is aligning people and fostering collaboration to achieve a common goal. For example, on my current job, commercial and sales ideas might be far from technical possibilities, and having to frame a project taking into account these different mindsets can be challenging. However, I believe that there is a possibility of merging technical and business decisions by fostering open communication, setting clear expectations, and translating technical constraints into business-friendly language, and vice versa.  
### Cons of current job

The aspects I find least fulfilling about my current position are the limited opportunities for innovation and creative problem-solving. Additionally, I feel that the focus on monitoring minor details, such as punctuality, sometimes overshadows an emphasis on achieving impactful results. This has led me to seek a role where creativity, innovation, and results-oriented work are more highly valued and supported.











**Conocimientos**

- [x] Compute Engine 
- [x] App Engine
- [x] Cloud Storage 
- [x] BigQuery,
- [x] Arquitectura de nube, 
- [x] Incluyendo redes, virtualización
- [ ] Identidad, seguridad, business continuity 
- [ ] Recuperación de desastres y gobernanza de datos.
- [ ] Docker y Kubernetes.
- [ ] Conocimientos en bases de datos cloud y herramientas de replicación de datos
- [ ] Comprensión de principios de DevOps y herramientas asociadas (CI/CD, monitoreo, logging).
- [ ] Escalabilidad, rentabilidad
- [ ] Migracion local y otras nubes a GCP
- [ ] Terraform y Cloud Deployment Manager
- [ ] Optimizacion de costos
- [ ] Soporte tecnico en entornos de GCP



##### GCP Costos:
- Provisioned: Asegurate de poder manejar X cantidad de datos o procesamiento
- Por uso: Usaré esto y quiero que me cobres por esto. 

##### GCP Compute Services 

| Servicio                     | Descripcion                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ---------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| GCE Google Compute Engine    | Let's you rent VM on demand (with OS<br>only). This is IaaS (Infrastructure as a Service) and it is similar to AWS EC2.<br>Custom CPU and RAM. Pay by the second (60 second min.). GCE has a sustained use<br>discount meaning that gets cheaper the more you use it. Cheaper for preemptible<br>(turn my VM off when they need the resource back). Live Migration: Google<br>seamlessly moves instance across hosts, as needed.                                  |
| GKE Google Kubernetes Engine | Managed Kubernetes cluster for<br>running Docker containers (with autoscaling). It was called Google Container Engine<br>(GKE). Comparable to AWS EC2 Container Service (ECS & EKS).<br>Integration with IAM<br>When you create a cluster,Google<br>automatically creates GCE instances (production cluster should have 3+ nodes, to<br>handle failures).                                                                                                         |
| Google App Engine            | Platform as a Service (PaaS) that<br>takes your code and runs it (similar to AWS Elastic Beanstalk or Heroku). Runs<br>almost any language. Auto-scaled based on load (NON FLEX mode can turn off last<br>instance when no traffic).                                                                                                                                                                                                                              |
| Google Cloud Run Functions   | Runs code in response to an event<br>(can be programmed in Node.js, Python, Java, Go). Functions as a Service (FaaS),<br>often referred to as Serverless. Similar to Lambda in AWS. Pay for CPU and RAM<br>assigned to function, per 100ms(min 100ms). Massively scalable (horizontally) - can<br>run many copies when needed. Useful when requests change a lot (not sure how many<br>people will use it), like chatbots, message processors, IoT or Automation. |

##### GCP Storage Services

| Service         | Description                                                                                                                                                                                                                   |
| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Cloud Filestore | Fully managed file based storage<br>Comparable to AWS EFS or NAS<br>Primary use case is application migration to cloud<br>Backups and snapshots available<br>Support GKE workloads. Multiple pods can have shared file system |
| GCS             | Infinitely scalable<br>Versioned<br>Object Storage<br>Similar a S3<br>You can setup redundancy, regionality, nearline access, coldline access                                                                                 |

##### GCP Databases

| Service        | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Cloud SQL      | Fully-managed and reliable MySQL and PostgreSQL<br>databases. Similar to AWS RDS. Supports automatic replication, backup, failover.<br>Scaling is manual (vertically and horizontally). Effectively pay for underlying GCE<br>instances and PDs.                                                                                                                                                                                                                                                                                                                                     |
| Cloud Spanner  | If you outgrow cloud sql,<br>use cloud spanner, the first horizontally scalable, strongly consistent, relational<br>database service. Can use it as a normal mysql db. Minimum 3 nodes for production<br>environments. NODE is a server on each of the replication locations. CAP theorem<br>(check). Cloud spanner gives Consistency, Partition-tolerance and 99.999% (five<br>nines) availability. Not based on fail-over, any of the servers can handel any of<br>the requests. Pay for provisioned node time. USE for seriously big database<br>(thousands of dollars per month) |
| BigQuery       | Serverless column-store data warehouse for<br>analytics using SQL. If you dont use queries, you dont pay for queries, only for<br>the saved data. Scales internally, it can scan TB in seconds and PB in minutes.<br>Similar to AWS Athena. Pay for GBs actually considered (scanned) during queries.<br>Attempts to reuse cached results, free. Pay for GBs added via streaming inserts.                                                                                                                                                                                            |
| Cloud Bigtable | NoSQL low latency & high throughput nosql DB for<br>large operational and analytical apps. Similar to AWS DynamoDB or Apache Hbase.<br>Supports open source HBase API. Integrates with Hadoop, Dataflow, Dataproc. Scales<br>seamlessly. Pay for processing node hours, pay for GB-hours used for storage. Made<br>Useful for time series & IoT data, as well as finance data<br>for huge workloads, if not, consider Cloud Datastore                                                                                                                                                |

##### Data Transfer

| Service                  | Description                                                                                                                                                                                                                                                                                                  |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Data Transfer Appliance  | Rackable, high-capacity storage server to physically ship data to GCS. Similar to AWS snowball. Ingest only, not a way to avoid egress charges. 100TB or 480TB versions. 480TB/week is very fast. This is useful when your data is in your datacenter, if it is not, you could use Storage Transfer Service. |
| Storage Transfer Service | GLOBAL service. Copies objects, destination is always GCS bucket, source can be S3, HTTP/HTTPS endpoint, or another GCS bucket. Onte time or scheduled recurring transfers. Free to use, but you pay for its actions.                                                                                        |
![[Pasted image 20250108194936.png]]
![[Pasted image 20250108200056.png]]

##### Security

**Service accounts:** Help implement better security. Identity & Access Management works with Members and
Roles. Members can be a specific person, group of people or a service account on
the domain 12345@cloudservices.gserviceaccount.com. Roles can be, for example,
Instance Admin, Pub/Sub Publisher, Storage Object Viewer, etc.
Service Accounts are created for a specific non-human task requiring granular
authorization. Identity can be assumed by an application/workload... in the form of
keys, which can be easily rotated.
GCP services assume service account identity.


Fault tolerance and loosely coupling with PUBSUB

Integrate security into CI/CD PIPELINES: Automate security checks and vulnerability scanning within your development and deployment processes. 

Servicio DLP: Ayuda a descubrir, clasificar y proteger informacion sensible

KMS: Manejo de claves criptograficas para los servicios en la nube. 

**medidas de seguridad dependerán:**
- requerimientos de compliance
- Tipos de datos
- Complejidad de la arquitectura
- Budget. 

ISO 27001


##### GCP Dataproc
Dataproc is a great choice for quickly migrating Hadoop and Spark workloads
into GCP
- The biggest benefits of Dataproc over a self-managed Hadoop or Spark
cluster are the ease of scaling, being able to use cloud Storage instead of HDFS,
and the connectors to other GCP services like BigQuery, BigTable.



##### BigQuery

![[Pasted image 20250108211813.png]]

![[Pasted image 20250108211907.png]]
![[Pasted image 20250108212044.png]]

Optimize costs: 
partition data
indexing 
denormalise correctly
![[Pasted image 20250108212329.png]]
![[Pasted image 20250108212339.png]]
![[Pasted image 20250108212355.png]]

![[Pasted image 20250108212420.png]]

![[Pasted image 20250108212453.png]]



### Disaster recovery
Disaster recovery is a subset of business continuity planning. Disaster recovery planning begins with a business impact analysis that defines two key metrics:
- RTO (Recovery Time Objective), which is the maximum acceptable length of time that your application can be offline. 
- RPO (Recovery Point Objective), which is the maximum acceptable length of time during which data might be lost from your application due to a major incident. 

![[Pasted image 20250108222214.png]]
The smaller your RTO and RPO values, the more your application will cost to run. 

#### DR patterns
DR patterns are considered to be *cold*, *warm*, or *hot*. These patterns indicate how readily the system can recover when something goes wrong. 



## My Questions
- What are the expectations for the first months in the role and what are the benchmarks for evaluating success?
- Who will I be working with?
- What does a typical day look like in this job?




Bluetab: consultoría: 
- BBVA 
- Modelo de trabajo híbrido 2 a 3 veces por semana (torre polanco o torre bbva)
- Nube GCP
- conozca servicios y soluciones que maneja la nube
- migración de aplicaciones datos y servicios locales a GCP están manejando DATIUM? 
- Entrevista técnica y finalmente una entrevista con BBVA. 
- Procesos internos (prueba psicométrica)
- AVISO DE PRIVACIDAD y machote cv corporativo para editarlo con mi información profesional (en inglés o español). 
- Reporte de semanas cotizadas del IMSS. 
- Beneficios: 
	- Salario: 35k
	- Sueldo bruto total 35k - bonos de puntualidad y asistencia
	- vales de despensa 2000 pesos 
	- Préstamos personales via nómina sin intereses
	- Programas por referidos 
	- bonos repartición de utilidades 
	- 18 días al año
	- Días feriados de ley y blue days 24 y 31 de diciembre y medio dia en cumpleaños
	- seguro de vida y gastos medicos menores
	- bono de bienestar 15 mil pesos para gimnasio, lentes o cosas similares de bienestar
	- 1500 pesos para psicólogo jajajaja
	- 10 mil pesos para cursos y certificados 
	- becas educativas dependiendo de desempeño 
